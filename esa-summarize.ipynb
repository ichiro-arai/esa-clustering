{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# esa-summarize\n",
    "The esa-summarize is created to understand the summarization effectively.\n",
    "\n",
    "This file consists of the following contents:\n",
    "- setup esa-summarize with dependencies\n",
    "- preparation to retrieve esa posts\n",
    "- retrieving posts\n",
    "- parse text files of posts\n",
    "- TF-IDF calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setup\n",
    "Before open this file, setup is needed as below:\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/ichiro-arai/esa-summarize.git\n",
    "$ cd esa-clustering\n",
    "$ brew install pyenv\n",
    "$ echo 'export PYENV_ROOT=\"${HOME}/.pyenv\"' >> ~/.bash_profile\n",
    "$ echo 'export PATH=\"$PATH:${PYENV_ROOT}/bin\"' >> ~/.bash_profile\n",
    "$ echo 'eval \"$(pyenv init -)\"' >> ~/.bash_profile\n",
    "$ source .bash_profile\n",
    "$ pyenv install anaconda3-4.1.1\n",
    "$ pyenv local anaconda3-4.1.1\n",
    "$ brew install mecab\n",
    "$ brew install mecab-ipadic\n",
    "$ pip install mecab-python3\n",
    "$ jupyter notebook\n",
    "```\n",
    "Then, open this ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO modify dictionary, append Wikipedia titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "token = os.environ['ESA_ACCESS_TOKEN']  # access token which is generated by https://[team].esa.io/user/tokens\n",
    "headers = {\n",
    "    'Authorization': 'Bearer {0}'.format(token)\n",
    "}\n",
    "prefix = 'https://api.esa.io'  # see https://docs.esa.io/posts/102\n",
    "\n",
    "team = os.environ['ESA_TEAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_load(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os.path\n",
    "\n",
    "def request_dump(request, filename):\n",
    "    r = requests.get(prefix + request, headers=headers)\n",
    "    dump(r, filename)\n",
    "\n",
    "def request_dump_if_not_exist(request, filename):\n",
    "    if (os.path.exists(filename)):\n",
    "        return\n",
    "    else:\n",
    "        request_dump(request, filename)\n",
    "\n",
    "def dump(res, filename):\n",
    "    assert res.status_code == 200\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = '/v1/teams/{0}/posts?include=stargazers,comments'.format(team)\n",
    "request_dump_if_not_exist(url, 'posts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### need this?:  get the list of post_number\n",
    "# import time\n",
    "# wait = (15 * 60) / 75  # api call limit of request is 75 times per 15 minutes\n",
    "#\n",
    "# def wait_retry(request_func, post_numbers):\n",
    "#     post_numbers = post_numbers.copy\n",
    "#     while (len(post_numbers) > 0):\n",
    "#         try:\n",
    "#             time.sleep(wait)\n",
    "#             post_num = post_numbers.pop(0)\n",
    "#             request_func(post_num)\n",
    "#         except Exception:\n",
    "#             print('failed: %d' % post_num)\n",
    "#             post_numbers.append(post_num)\n",
    "#\n",
    "# def request_func(post_num):\n",
    "#     url = '/v1/teams/{0}/posts/{1}?include=comments'.format(team, post_num)\n",
    "#     filename = 'post-{0}.json'.format(post_num)\n",
    "#     request_dump_if_not_exist(url, filename)\n",
    "#\n",
    "# posts_json = json_load('posts.json')\n",
    "# post_numbers = [post['number'] for post in posts_json['posts']]\n",
    "# wait_retry(request_func, post_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parse text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts = json_load('posts.json')['posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filename(post):\n",
    "    return 'parsed-post-{0}.csv'.format(post['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "def to_itr(res):\n",
    "    while res:\n",
    "        yield res\n",
    "        res = res.next\n",
    "\n",
    "mecab = MeCab.Tagger('-Ochasen')\n",
    "mecab.parse('')  # magic not to be Garbage Collected\n",
    "\n",
    "for post in posts:\n",
    "    with open(filename(post), 'w') as f:\n",
    "        parsed = mecab.parseToNode(post['body_md'])\n",
    "        nouns = [i.surface for i in to_itr(parsed) if i.feature.split(',')[0] == '名詞']\n",
    "        f.writelines(map(lambda x: x + '\\n', nouns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF for each user post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = [filename(post) for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input='filename')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "tfidfs = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_index(posts, pred):\n",
    "    filtered = filter(pred, enumerate(posts))\n",
    "    return map(lambda t: t[0], filtered)\n",
    "\n",
    "def find_user_posts(posts, user):\n",
    "    return find_index(posts, lambda post: post[1]['created_by']['screen_name'] == user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_users = set(map(lambda t: t['created_by']['screen_name'], posts))\n",
    "\n",
    "n = 50\n",
    "for user in all_users:\n",
    "    print('-' * 10)\n",
    "    print(user)\n",
    "    for i in find_user_posts(posts, user):\n",
    "        tfidf_array = tfidfs[i]\n",
    "        top_n_idx = tfidf_array.argsort()[-n:][::-1]\n",
    "        words = [terms[idx] for idx in top_n_idx]\n",
    "        print('{0}. {1}: '.format(posts[i]['number'], posts[i]['name']))\n",
    "        print(words)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization by each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
